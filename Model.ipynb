{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = pd.read_csv(r'D:\\hse_hw\\news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка ресурсов NLTK\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# Функции для предобработки текста\n",
    "def remove_patterns(text):\n",
    "    \"\"\"Очищает текст от символов, цифр, пунктуации и нежелательных паттернов.\"\"\"\n",
    "    # Удаление всего до вхождения '/' \n",
    "    text = re.sub(r'^.*?/', '', text)\n",
    "    # Удаление упоминаний \"РИА Новости\" и двух следующих слов\n",
    "    text = re.sub(r'\\bРИА Новости\\b(?:\\s+\\w+){1,2}', '', text)\n",
    "    # Удаление упоминаний \"Reuters\" и двух следующих слов\n",
    "    text = re.sub(r'\\bReuters\\b(?:\\s+\\w+){1,2}', '', text)\n",
    "    # Удаление оставшейся пунктуации, символов, цифр\n",
    "    text = re.sub(r'[^а-яё\\s]', '', text.lower())\n",
    "    return text.strip()\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Очищает текст от символов, цифр и пунктуации.\"\"\"\n",
    "    text = remove_patterns(text)\n",
    "    text = re.sub(r'[^а-яё\\s]', '', text.lower())\n",
    "    return text.strip()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Удаляет стоп-слова и лемматизирует текст.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Проводит полную предобработку текста.\"\"\"\n",
    "    df = df.dropna(subset=['text'])\n",
    "    df = df[df['text'].str.len() > 5]\n",
    "    df['processed_text'] = df['text'].map(clean_text).map(preprocess_text)\n",
    "    return df\n",
    "\n",
    "# Предобработка данных\n",
    "tbl = preprocess_data(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование текста в векторы\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "scaler = MaxAbsScaler()\n",
    "X = vectorizer.fit_transform(tbl['processed_text'])\n",
    "X = scaler.fit_transform(X)\n",
    "y = tbl['topic']\n",
    "\n",
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Определение пайплайнов для моделей\n",
    "pipelines = {\n",
    "    'RandomForest': Pipeline([('classifier', RandomForestClassifier(random_state=42))]),\n",
    "    'ExtraTrees': Pipeline([('classifier', ExtraTreesClassifier(random_state=42))]),\n",
    "    'SVM': Pipeline([('classifier', SVC(probability=True, random_state=42))]),\n",
    "    'LogisticRegression': Pipeline([('classifier', LogisticRegression(max_iter=1000, random_state=42))]),\n",
    "    'CatBoost': Pipeline([('classifier', CatBoostClassifier(verbose=0, random_state=42))]),\n",
    "}\n",
    "\n",
    "# Определение параметров для RandomizedSearchCV\n",
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [10, 20, 30],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "    },\n",
    "    'ExtraTrees': {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [10, 20, 30],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "    },\n",
    "    'SVM': {\n",
    "        'classifier__C': [0.1, 1, 10, 100],\n",
    "        'classifier__kernel': ['linear', 'rbf', 'poly'],\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'classifier__C': [0.1, 1, 10, 100],\n",
    "        'classifier__penalty': ['l2'],\n",
    "        'classifier__solver': ['lbfgs', 'liblinear']\n",
    "    },\n",
    "    'CatBoost': {\n",
    "    'classifier__iterations': [100],\n",
    "    'classifier__depth': [6, 8],\n",
    "    'classifier__learning_rate': [0.1, 0.2]\n",
    "    }\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV для каждой модели\n",
    "search_results = {}\n",
    "metrics = []\n",
    "\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    search = RandomizedSearchCV(pipeline, param_grids[model_name], n_iter=5, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "    search.fit(X_train, y_train)\n",
    "    search_results[model_name] = search.best_estimator_\n",
    "\n",
    "    # Оценка метрик\n",
    "    y_pred = search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Вывод classification_report\n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Сохранение результатов\n",
    "    metrics.append({'Model': model_name, 'Accuracy': accuracy, 'F1-score': f1})\n",
    "\n",
    "# Блендинг моделей\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(name, model) for name, model in search_results.items()],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Оценка метрик VotingClassifier\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "f1_voting = f1_score(y_test, y_pred_voting, average='weighted')\n",
    "\n",
    "# Вывод classification_report для VotingClassifier\n",
    "print(\"\\nClassification Report for VotingClassifier:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n",
    "\n",
    "metrics.append({'Model': 'VotingClassifier', 'Accuracy': accuracy_voting, 'F1-score': f1_voting})\n",
    "\n",
    "# Таблица метрик\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Отображение таблицы\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report for RandomForest:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.59      0.84      0.70      1394\n",
    "         1.0       0.79      0.68      0.73       667\n",
    "         2.0       0.82      0.85      0.84       647\n",
    "         3.0       0.73      0.79      0.76       948\n",
    "         4.0       0.97      0.94      0.95       417\n",
    "         5.0       0.90      0.81      0.85       218\n",
    "         6.0       0.84      0.63      0.72       984\n",
    "         7.0       0.91      0.58      0.71       273\n",
    "         8.0       0.93      0.35      0.51       320\n",
    "\n",
    "    accuracy                           0.75      5868\n",
    "   macro avg       0.83      0.72      0.75      5868\n",
    "weighted avg       0.78      0.75      0.74      5868\n",
    "\n",
    "\n",
    "Classification Report for ExtraTrees:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.56      0.88      0.69      1394\n",
    "         1.0       0.81      0.64      0.71       667\n",
    "         2.0       0.85      0.87      0.86       647\n",
    "         3.0       0.75      0.75      0.75       948\n",
    "         4.0       0.97      0.93      0.95       417\n",
    "         5.0       0.94      0.73      0.82       218\n",
    "         6.0       0.81      0.57      0.67       984\n",
    "         7.0       0.92      0.59      0.72       273\n",
    "         8.0       0.94      0.37      0.53       320\n",
    "\n",
    "    accuracy                           0.73      5868\n",
    "   macro avg       0.84      0.70      0.74      5868\n",
    "weighted avg       0.77      0.73      0.73      5868\n",
    "\n",
    "\n",
    "Classification Report for SVM:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.80      0.86      0.83      1394\n",
    "         1.0       0.78      0.80      0.79       667\n",
    "         2.0       0.88      0.92      0.90       647\n",
    "         3.0       0.80      0.87      0.83       948\n",
    "         4.0       0.97      0.98      0.97       417\n",
    "         5.0       0.93      0.94      0.93       218\n",
    "         6.0       0.76      0.62      0.68       984\n",
    "         7.0       0.91      0.86      0.89       273\n",
    "         8.0       0.89      0.82      0.86       320\n",
    "\n",
    "    accuracy                           0.83      5868\n",
    "   macro avg       0.86      0.85      0.85      5868\n",
    "weighted avg       0.83      0.83      0.83      5868\n",
    "\n",
    "\n",
    "Classification Report for LogisticRegression:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.82      0.87      0.84      1394\n",
    "         1.0       0.80      0.81      0.81       667\n",
    "         2.0       0.90      0.92      0.91       647\n",
    "         3.0       0.82      0.86      0.84       948\n",
    "         4.0       0.97      0.98      0.98       417\n",
    "         5.0       0.95      0.94      0.95       218\n",
    "         6.0       0.78      0.70      0.74       984\n",
    "         7.0       0.92      0.86      0.89       273\n",
    "         8.0       0.90      0.81      0.85       320\n",
    "\n",
    "    accuracy                           0.84      5868\n",
    "   macro avg       0.87      0.86      0.87      5868\n",
    "weighted avg       0.84      0.84      0.84      5868\n",
    "\n",
    "\n",
    "\n",
    "Classification Report for CatBoost:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.71      0.85      0.77      1394\n",
    "         1.0       0.80      0.84      0.82       667\n",
    "         2.0       0.88      0.87      0.87       647\n",
    "         3.0       0.79      0.84      0.81       948\n",
    "         4.0       0.97      0.94      0.96       417\n",
    "         5.0       0.93      0.90      0.92       218\n",
    "         6.0       0.99      0.76      0.86       984\n",
    "         7.0       0.91      0.78      0.84       273\n",
    "         8.0       0.92      0.67      0.77       320\n",
    "\n",
    "    accuracy                           0.83      5868\n",
    "   macro avg       0.88      0.83      0.85      5868\n",
    "weighted avg       0.84      0.83      0.83      5868\n",
    "\n",
    "\n",
    "Classification Report for VotingClassifier:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.82      0.88      0.85      1394\n",
    "         1.0       0.83      0.83      0.83       667\n",
    "         2.0       0.90      0.93      0.91       647\n",
    "         3.0       0.82      0.88      0.85       948\n",
    "         4.0       0.98      0.98      0.98       417\n",
    "         5.0       0.94      0.94      0.94       218\n",
    "         6.0       0.85      0.72      0.78       984\n",
    "         7.0       0.91      0.87      0.89       273\n",
    "         8.0       0.92      0.80      0.86       320\n",
    "\n",
    "    accuracy                           0.86      5868\n",
    "   macro avg       0.88      0.87      0.88      5868\n",
    "weighted avg       0.86      0.86      0.86      5868\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Model</th>\n",
    "      <th>Accuracy</th>\n",
    "      <th>F1-score</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>RandomForest</td>\n",
    "      <td>0.746080</td>\n",
    "      <td>0.743718</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>ExtraTrees</td>\n",
    "      <td>0.733810</td>\n",
    "      <td>0.732001</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>SVM</td>\n",
    "      <td>0.829073</td>\n",
    "      <td>0.826704</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>LogisticRegression</td>\n",
    "      <td>0.844751</td>\n",
    "      <td>0.843857</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>CatBoost</td>\n",
    "      <td>0.829755</td>\n",
    "      <td>0.831549</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>VotingClassifier</td>\n",
    "      <td>0.857532</td>\n",
    "      <td>0.856638</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия оказалась наилучшей моделью(не учитывая объединенеие моделей) для задачи классификации новостей, что может быть связано с её сбалансированными характеристиками и хорошей производительностью в случае классификации текстовых данных с дисбалансом классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Честно ожидал других результов, не могу предположить почему логистичекская регрессия оказалась лучше других моделей\n",
    "Возможно еще что у CatBoost было очень мало гиперпарметров, я это сделал намеренно, так как обучение было слишком догим\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как можно улучшить модель:\n",
    "- использовать предобученные модели для превращения текста в новости \n",
    "- использовать DL\n",
    "- Расширить диапазон гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Сохранение модели VotingClassifier\n",
    "joblib.dump(voting_clf, r'D:\\hse_hw\\final_voting_model.pkl')\n",
    "\n",
    "print(\"Модель успешно сохранена в файл 'final_voting_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\hse_hw\\test_news.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'content': 'text'}, inplace=True) \n",
    "df = preprocess_data(df)\n",
    "X = vectorizer.transform(df['processed_text'])\n",
    "X = scaler.transform(X)\n",
    "df['prediction'] = voting_clf.predict(X)\n",
    "df = df.reset_index()\n",
    "output_path = r\"D:\\hse_hw\\test_news_predictions.csv\"\n",
    "df[['prediction', 'index']].to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Результаты предсказаний сохранены в {output_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
